{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: - "
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge keras --yes\n",
    "!conda install -c anaconda tensorflow-gpu --yes\n",
    "!conda install -c anaconda gensim --yes\n",
    "!conda install -c spacy spacy --yes\n",
    "!pip install kapre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import sys\n",
    "import skvideo.io\n",
    "from skvideo.measure import scenedet\n",
    "import json\n",
    "from scipy.signal import argrelextrema\n",
    "import urllib\n",
    "from urlparse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time as t\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('lmtd')\n",
    "from lmtd9 import LMTD\n",
    "from lmtd9 import database as db\n",
    "from lmtd9 import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librosa for audio\n",
    "import librosa\n",
    "# And the display module for visualization\n",
    "import librosa.display\n",
    "import glob\n",
    "import os\n",
    "\n",
    "#import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "from sklearn import preprocessing\n",
    "#from keras.utils.np_utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffmpeg_load_audio import ffmpeg_load_audio\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import requests\n",
    "import urlparse, os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import operator\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import time\n",
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND']='tensorflow'\n",
    "from keras import utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from keras import applications\n",
    "from keras.layers import GlobalAveragePooling2D, merge, Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import TimeDistributed, BatchNormalization\n",
    "from keras.layers import Input, Convolution1D, GlobalMaxPooling1D, merge, Dense, Dropout\n",
    "from keras.layers import Activation, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kapre.time_frequency import Melspectrogram\n",
    "from kapre.utils import Normalization2D\n",
    "from kapre.augmentation import AdditiveNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 50,\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "gaussian_noise_lstm = 0.01\n",
    "lstm_size = 512\n",
    "gru_size = 512\n",
    "recurrent_dropout = 0.2\n",
    "dropout_cnn = 0.5\n",
    "gaussian_noise_cnn = 0.1\n",
    "model_output_path = \"/home/paulo/mestrado/MovieGenreClassifier.model\"\n",
    "validation_split = 0.2\n",
    "test_split = 0.2\n",
    "regularizer_lambda = 0.01\n",
    "GLOVE_DIR = \"/home/paulo/mestrado/glove.6B/\"\n",
    "min_word_frequency_word2vec = 5,\n",
    "embed_size_word2vec = 300\n",
    "context_window_word2vec = 10\n",
    "MAX_NB_WORDS = 50000\n",
    "max_sentence_len = 300\n",
    "maxlen = max_sentence_len\n",
    "min_sentence_length = 15\n",
    "sr = 44100 #sampling rate 44.1KHz\n",
    "audio_channels = 2\n",
    "width = 299 #for inceptionV3\n",
    "height = 299 #for inceptionV3   \n",
    "depth = 3 #rgb\n",
    " #stereo\n",
    "audio_input_shape = (audio_channels, sr) #2-channels - 44.1KHz\n",
    "time_steps = 240\n",
    "nb_features = 2048\n",
    "nb_classes = 9\n",
    "conv_filters = 384\n",
    "dropout = 0.5\n",
    "max_epochs = 10\n",
    "\n",
    "n_cpus = multiprocessing.cpu_count()    \n",
    "print('n_cpus:',n_cpus)      \n",
    "number_gpus = 1\n",
    "number_cpus = n_cpus-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmtd = LMTD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def setup_word2vec(all_data):    \n",
    "    wordvec_model = Word2Vec(all_data, min_count=min_word_frequency_word2vec, size=embed_size_word2vec, window=context_window_word2vec)\n",
    "    return wordvec_model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_tokenizer(all_data):\n",
    "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "    tokenizer.fit_on_texts(all_data)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_glove_embeddings():\n",
    "    embeddings_index = {}\n",
    "    glove_file = 'glove.6B.{}d.txt'.format(embed_size_word2vec) #need to make both to match (embed_size_word2vec and globe index)\n",
    "    f = open(os.path.join(GLOVE_DIR, glove_file))\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_embeddings_matrices(embeddings_index, word_index):\n",
    "    embedding_matrix = np.random.random((len(word_index) + 1, embed_size_word2vec))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_embedding_layer(word_index, embedding_matrix):\n",
    "    embedding_layer = Embedding(len(word_index) + 1,\n",
    "                                embed_size_word2vec,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=max_sentence_len,\n",
    "                                trainable=True)\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createHistograms(img):\n",
    "    hsv_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    hue, sat, ilum = hsv_image[:,:,0], hsv_image[:,:,1], hsv_image[:,:,2]    \n",
    "    hist_hue, bin_edges_hue = np.histogram(np.ndarray.flatten(hue), bins=8)\n",
    "    hist_sat, bin_edges_sat = np.histogram(np.ndarray.flatten(sat), bins=4)\n",
    "    hist_ilum, bin_edges_ilum = np.histogram(np.ndarray.flatten(ilum), bins=4)\n",
    "    return np.hstack((hist_hue, hist_sat, hist_ilum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_intersection(previousHist, currentHist):\n",
    "    s_i = 0\n",
    "    #for each bin \n",
    "    #print(currentHist.shape[0])\n",
    "    for j in range(currentHist.shape[0]):\n",
    "        min_bin_s_i = min(currentHist[j],previousHist[j])\n",
    "        #print('minimum from bin {}: {}'.format(j,min_bin_s_i))\n",
    "        min_sum_prev = sum(previousHist)\n",
    "        min_sum_cur = sum(currentHist)\n",
    "        min_both = min(min_sum_prev, min_sum_cur) #normalize (maximum can be 1)\n",
    "        s_i+= (min_bin_s_i/float(min_both)) \n",
    "    return s_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradE(sNext, sCurrent):\n",
    "    return sNext-sCurrent\n",
    "\n",
    "def gradW(sPrevious, sCurrent):\n",
    "    return sPrevious-sCurrent\n",
    "\n",
    "def gaussianKernel(x, k=0.1):\n",
    "    return np.exp(-(x/k)**2)\n",
    "\n",
    "def smoothed_s(s_i_previous, s_i, s_i_next, lamb=0.1, k=0.1):\n",
    "    gEi = gradE(s_i_next, s_i)\n",
    "    gWi = gradW(s_i_previous, s_i)\n",
    "    CEt = gaussianKernel(np.absolute(gEi))\n",
    "    CWt = gaussianKernel(np.absolute(gWi))\n",
    "    stnext_i = s_i + lamb*(CEt*gEi + CWt * gWi)\n",
    "    return stnext_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image = 'images/paulo_meire.png'\n",
    "img = cv2.imread(target_image)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image2 = 'images/paulo_meire2.png'\n",
    "img2 = cv2.imread(target_image2)\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist1 = createHistograms(img)\n",
    "plt.hist(hist1)\n",
    "print(hist1)\n",
    "hist2 = createHistograms(img2)\n",
    "plt.hist(hist2)\n",
    "print(hist2)\n",
    "print(histogram_intersection(hist1, hist2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_variance(videodata, smooth_scene_cuts):\n",
    "    Ls = []\n",
    "    Us = []\n",
    "    Vs = []\n",
    "    for frame in smooth_scene_cuts:\n",
    "        luv_image = cv2.cvtColor(frame, cv2.COLOR_RGB2Luv)\n",
    "        L, u, v = luv_image[:,:,0], luv_image[:,:,1], luv_image[:,:,2]\n",
    "        Ls.append(L)\n",
    "        Us.append(u)\n",
    "        Vs.append(v)        \n",
    "    Luv = np.stack((np.array(Ls).flatten(), np.array(Us).flatten(), np.array(Vs).flatten()), axis=0)\n",
    "    pCov = np.cov(Luv)\n",
    "    #print('covLuv:', pCov)\n",
    "    #print('varL:',np.var(np.array(Ls)))\n",
    "    #print('varU:',np.var(np.array(Us)))\n",
    "    #print('varV:',np.var(np.array(Vs)))\n",
    "    totalColorVariance = np.linalg.det(pCov)\n",
    "    #print('totalColorVariance:', totalColorVariance)\n",
    "    return totalColorVariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trailer_ids = lmtd.train_ids\n",
    "comedy_id = None\n",
    "horror_id = None\n",
    "action_id = None\n",
    "\n",
    "for _id in trailer_ids:\n",
    "    # Returns a dictionary in which keys are the queried trailer_ids\n",
    "    movie_data = lmtd.get_data_by_trailer_ids(_id)\n",
    "    #print(movie_data)\n",
    "    for metadata in movie_data.keys():\n",
    "        print('trailer id : ', metadata)\n",
    "        print('title db : ', movie_data[metadata]['Title'])\n",
    "        print('genres db : ', movie_data[metadata]['Genre'])\n",
    "        print('labels       : ', lmtd.train_labels[int(metadata)])\n",
    "        print('re-converted : ', lmtd.binary_label_to_genre(lmtd.train_labels[int(metadata)])[0])\n",
    "        if comedy_id is not None and horror_id is not None and action_id is not None:\n",
    "            break  \n",
    "        elif ('Comedy' in movie_data[metadata]['Genre']):\n",
    "            comedy_id = _id\n",
    "        elif ('Horror' in movie_data[metadata]['Genre']):    \n",
    "            horror_id = _id            \n",
    "        elif ('Action' in movie_data[metadata]['Genre']):    \n",
    "            action_id = _id \n",
    "print('Comedy:',comedy_id)\n",
    "print('Horror:',horror_id)\n",
    "print('Action:',action_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lighting Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lighting_key(videodata, smooth_scene_cuts):    \n",
    "    hsv_images = []\n",
    "    for frame in smooth_scene_cuts:\n",
    "        hsv_image = cv2.cvtColor(frame, cv2.COLOR_RGB2HSV)\n",
    "        hsv_images.append(hsv_image)        \n",
    "    meanHsv = np.mean(hsv_images)\n",
    "    stdHsv = np.std(hsv_images)\n",
    "    lightingkey = meanHsv * stdHsv\n",
    "    #print(lightingkey)\n",
    "    return lightingkey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motion_content(videodata, smooth_scene_cuts, w=3):    \n",
    "    frameOld = smooth_scene_cuts[0]     \n",
    "    count_active_pixels = 0\n",
    "    count_all_pixels = 0\n",
    "    for currentFrame in smooth_scene_cuts:\n",
    "        Hx = cv2.Sobel(currentFrame,cv2.CV_64F,1,0,ksize=w)\n",
    "        #print('Hx:',Hx)\n",
    "        Ht = currentFrame - frameOld  #temporal derivative\n",
    "        #print('Ht:',Ht)\n",
    "        Hx2 = Hx * Hx\n",
    "        #print('Hx2:',Hx2)\n",
    "        Ht2 = Ht * Ht\n",
    "        #print('Ht2:',Ht2)\n",
    "        HxHt = Hx * Ht\n",
    "        #print('HxHt:',HxHt)\n",
    "        Jxx = sum(Hx2)\n",
    "        #print('Jxx:',Jxx)\n",
    "        Jxt = sum(HxHt)\n",
    "        #print('Jxt:',Jxt)\n",
    "        Jtt = sum(Ht2)\n",
    "        #print('Jtt:',Jtt)\n",
    "        #print(2*Jxt/(Jxx-Jxt))\n",
    "        theta = (1/2.0)*np.degrees(np.arctan(2*Jxt/(Jxx-Jxt)))\n",
    "        count_all_pixels+= theta.size  \n",
    "        #print(count_all_pixels)\n",
    "        aux = theta[~np.isnan(theta)]\n",
    "        aux = aux.flatten()\n",
    "        #print(aux)\n",
    "        count_active_pixels += aux[(0.0 < aux) | (aux < 10.0)].size\n",
    "        #print(count_active_pixels)\n",
    "        frameOld = currentFrame        \n",
    "    return count_active_pixels/float(count_all_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comedy_filename = 'trailers/videos/'+comedy_id+'.mp4'\n",
    "horror_filename = 'trailers/videos/'+horror_id+'.mp4'\n",
    "action_filename = 'trailers/videos/'+action_id+'.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comedy_videometadata = skvideo.io.ffprobe(comedy_filename)\n",
    "print(comedy_videometadata.keys())\n",
    "print(json.dumps(comedy_videometadata[\"video\"], indent=4))\n",
    "print(json.dumps(comedy_videometadata[\"audio\"], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comedy_videodata = skvideo.io.vread(comedy_filename)\n",
    "print(comedy_videodata.shape)\n",
    "T, M, N, C = comedy_videodata.shape\n",
    "\n",
    "print(\"Number of frames: %d\" % (T,))\n",
    "print(\"Number of rows: %d\" % (M,))\n",
    "print(\"Number of cols: %d\" % (N,))\n",
    "print(\"Number of channels: %d\" % (C,))\n",
    "\n",
    "frame_rate = comedy_videometadata['video']['@avg_frame_rate']\n",
    "num_frames = np.int(comedy_videodata.shape[0])\n",
    "width = np.int(comedy_videometadata['video']['@width'])\n",
    "height = np.int(comedy_videometadata['video']['@height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the \"luminance\" algorithm\n",
    "comedy_scene_lum_idx = skvideo.measure.scenedet(comedy_videodata, method='histogram', parameter1=1.0)\n",
    "comedy_scenecuts = comedy_videodata[comedy_scene_lum_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(comedy_scenecuts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shot_detection(videodata):\n",
    "    #videodata = skvideo.io.vread(movie_filename)\n",
    "    #T, M, N, C = videodata.shape\n",
    "    #videometadata = skvideo.io.ffprobe(movie_filename)\n",
    "    #frame_rate = videometadata['video']['@avg_frame_rate']\n",
    "    #num_frames = np.int(videodata.shape[0])\n",
    "    #width = np.int(videometadata['video']['@width'])\n",
    "    #height = np.int(videometadata['video']['@height'])\n",
    "    numFrames, height, width, channels = videodata.shape\n",
    "    smooth_list = []\n",
    "    for t in range(2, numFrames-1):\n",
    "        beforePrevHist = createHistograms(videodata[t-2])\n",
    "        prevHist = createHistograms(videodata[t-1])\n",
    "        currHist = createHistograms(videodata[t])\n",
    "        nextHist = createHistograms(videodata[t+1])\n",
    "        s_i_prev = histogram_intersection(beforePrevHist,prevHist)\n",
    "        s_i_cur = histogram_intersection(prevHist,currHist)\n",
    "        s_i_next = histogram_intersection(currHist,nextHist)  \n",
    "        s_smooth = smoothed_s(s_i_prev, s_i_cur, s_i_next)\n",
    "        smooth_list.append(s_smooth)    \n",
    "    #if first derivative very near 0 (critical point) and second derivative > 0 (local minima)    \n",
    "    local_minima_index = argrelextrema(np.array(smooth_list), np.less)\n",
    "    #print(local_minima_index)\n",
    "    #intersects with normal histogram method ()\n",
    "    threshold_index = [i for i,v in enumerate(smooth_list) if v < 0.7]\n",
    "    cut_scene_index = sorted(list(set(local_minima_index[0]).intersection(threshold_index)))  \n",
    "    #print('Shots detected:', len(cut_scene_index))\n",
    "    #print('Index cut scenes:', cut_scene_index)\n",
    "    #plt.ylabel('Shot Detection')\n",
    "    #plt.xlabel('Frames')\n",
    "    #plt.show()   \n",
    "    smooth_scene_cuts = videodata[cut_scene_index]\n",
    "    return videodata, smooth_scene_cuts\n",
    "\n",
    "def average_shot_length(videodata, smooth_scene_cuts):\n",
    "    num_frames = np.int(videodata.shape[0])\n",
    "    return num_frames/float(len(smooth_scene_cuts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Histogram Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in comedy_scenecuts:\n",
    "    imgplot = plt.imshow(frame)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothed Histogram Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comedy_videodata, comedy_smooth_scene_cuts = shot_detection(comedy_videodata)\n",
    "for frame in comedy_smooth_scene_cuts:\n",
    "    imgplot = plt.imshow(frame)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "horror_videodata, horror_smooth_scene_cuts = shot_detection(horror_filename)\n",
    "for frame in horror_smooth_scene_cuts:\n",
    "    imgplot = plt.imshow(frame)\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "action_videodata, action_smooth_scene_cuts = shot_detection(action_filename)\n",
    "for frame in action_smooth_scene_cuts:\n",
    "    imgplot = plt.imshow(frame)\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Shot Length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Comedy Average shot length:', average_shot_length(comedy_videodata, comedy_smooth_scene_cuts))\n",
    "#print('Horror Average shot length:', average_shot_length(horror_videodata, horror_smooth_scene_cuts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Comedy Color Variance:', color_variance(comedy_videodata, comedy_smooth_scene_cuts))\n",
    "#print('Horror Color Variance:', color_variance(horror_videodata, horror_smooth_scene_cuts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lighting Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High value - comedy\n",
    "### Low value - horror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Comedy Lighting Key:', lighting_key(comedy_videodata, comedy_smooth_scene_cuts))\n",
    "#print('Horror Lighting Key:', lighting_key(horror_videodata, horror_smooth_scene_cuts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Comedy Motion Content:', motion_content(comedy_videodata, comedy_smooth_scene_cuts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Horror Motion Content:', motion_content(horror_videodata, horror_smooth_scene_cuts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Action Motion Content:', motion_content(action_videodata, action_smooth_scene_cuts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_features(audio_path):    \n",
    "    y, sample_rate = librosa.load(audio_path)\n",
    "    S = librosa.feature.melspectrogram(y, sr=sample_rate, n_mels=128)\n",
    "    log_S = librosa.amplitude_to_db(S, ref=np.max)\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "    tempo_bpm, beats = librosa.beat.beat_track(y=y_percussive, sr=sample_rate)\n",
    "    stft = np.abs(librosa.stft(y))\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sample_rate)[0]\n",
    "    spec_bandwith = librosa.feature.spectral_bandwidth(y=y, sr=sample_rate)[0]\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=S, sr=sample_rate))\n",
    "    flatness = librosa.feature.spectral_flatness(y=y)[0]\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sample_rate)[0]\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y)[0]\n",
    "    mfcc        = librosa.feature.mfcc(y=y, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs = np.mean(mfcc.T,axis=0)\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=y_harmonic,sr=sample_rate).T,axis=0)\n",
    "    hop_length = 512\n",
    "    oenv = librosa.onset.onset_strength(y=y, sr=sample_rate, hop_length=hop_length)\n",
    "    tempogram = librosa.feature.tempogram(onset_envelope=oenv, sr=sample_rate, hop_length=hop_length)\n",
    "    tempogram_ravel = np.ravel(tempogram)\n",
    "    # Compute global onset autocorrelation\n",
    "    ac_global = librosa.autocorrelate(oenv, max_size=tempogram.shape[0])\n",
    "    ac_global = librosa.util.normalize(ac_global)   \n",
    "    return mfccs, chroma_stft, mel,contrast,tonnetz, tempo_bpm, spectral_centroid, spec_bandwith, flatness, rolloff, zero_crossing_rate, oenv, tempogram_ravel, ac_global\n",
    "\n",
    "def extract_audio_features_melspectrogram(audio_path): \n",
    "    y, sample_rate = librosa.load(audio_path)\n",
    "    return y, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_audio_features(comedy_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(link, filelocation):\n",
    "    r = requests.get(link, stream=True)\n",
    "    with open(filelocation, 'wb') as f:\n",
    "        for chunk in r.iter_content(1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "                \n",
    "def createNewDownloadThread(link, filelocation):\n",
    "    download_thread = threading.Thread(target=download, args=(link,filelocation))\n",
    "    download_thread.start()\n",
    "\n",
    "def download_poster(movie_data, _id, folder): \n",
    "    time.sleep(0.1)\n",
    "    poster_url = movie_data[_id]['Poster']\n",
    "    print('Poster URL:', poster_url)\n",
    "    filename = poster_url[poster_url.rfind(\"/\")+1:]\n",
    "    print('filename:', filename)\n",
    "    file_str = \"/home/paulo/mestrado/posters/\" + folder + \"/\" + _id + \".jpg\"\n",
    "    print('file:', file_str)    \n",
    "    createNewDownloadThread(poster_url, file_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_statistics(feature_values):    \n",
    "    _mean = np.mean(feature_values)\n",
    "    _var = np.var(feature_values)\n",
    "    _skew = scipy.stats.skew(feature_values)\n",
    "    _kurtosis = scipy.stats.kurtosis(feature_values)\n",
    "    _median = np.median(feature_values)\n",
    "    _min = np.min(feature_values)\n",
    "    _max = np.max(feature_values)\n",
    "    return _mean, _var, _skew, _kurtosis, _median, _min, _max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_movie(movie_data, trailer_labels, _id, i, Y, features, Genres, FullPlots, spectograms):        \n",
    "    trailer_id = _id\n",
    "    title_db = movie_data[_id]['Title']\n",
    "    genres_db = movie_data[_id]['Genre']\n",
    "    if 'FullPlot' in movie_data[_id].keys() and movie_data[_id]['FullPlot'] is not None:\n",
    "          full_plot = movie_data[_id]['FullPlot']\n",
    "    else:\n",
    "          full_plot = movie_data[_id]['Plot']    \n",
    "    labels = trailer_labels[i]                                \n",
    "    avg_shot_length = 0\n",
    "    color_var = 0\n",
    "    light_key = 0\n",
    "    mot_content = 0\n",
    "    print((i, trailer_id, title_db, genres_db, labels, full_plot))\n",
    "    Y[i] = labels\n",
    "    Genres.append(genres_db)\n",
    "    FullPlots.append(full_plot.lower())\n",
    "    filename = 'trailers/videos/'+trailer_id+'.mp4'\n",
    "    try:\n",
    "            videodata = skvideo.io.vread(filename, num_frames=2000)\n",
    "            #_, smooth_scene_cuts = shot_detection(videodata)\n",
    "            scene_lum_idx = skvideo.measure.scenedet(videodata, method='histogram', parameter1=1.0)\n",
    "            smooth_scene_cuts = videodata[scene_lum_idx]\n",
    "            avg_shot_length = average_shot_length(videodata, smooth_scene_cuts)                \n",
    "            color_var = color_variance(videodata, smooth_scene_cuts)\n",
    "            light_key = lighting_key(videodata, smooth_scene_cuts)\n",
    "            mot_content = motion_content(videodata, smooth_scene_cuts)        \n",
    "            y, sr = extract_audio_features_melspectrogram(filename)   \n",
    "            print(y.shape)\n",
    "            spectograms[i] = y\n",
    "            \n",
    "            '''\n",
    "            mfccs, chroma_stft, mel,contrast,tonnetz, tempo_bpm, spectral_centroid, spec_bandwith, flatness, rolloff, zero_crossing_rate, oenv, tempogram, ac_global = extract_audio_features(filename)                        \n",
    "            mfccs_mean, mfccs_var, mfccs_skew, mfccs_kurtosis, mfccs_median, mfccs_min, mfccs_max = extract_statistics(mfccs)\n",
    "            chroma_stft_mean, chroma_stft_var, chroma_stft_skew, chroma_stft_kurtosis, chroma_stft_median, chroma_stft_min, chroma_stft_max = extract_statistics(chroma_stft)        \n",
    "            mel_mean, mel_var, mel_skew, mel_kurtosis, mel_median, mel_min, mel_max = extract_statistics(mel)\n",
    "            contrast_mean, contrast_var, contrast_skew, contrast_kurtosis, contrast_median, contrast_min, contrast_max = extract_statistics(contrast)\n",
    "            tonnetz_mean, tonnetz_var, tonnetz_skew, tonnetz_kurtosis, tonnetz_median, tonnetz_min, tonnetz_max = extract_statistics(tonnetz)\n",
    "            spectral_centroid_mean, spectral_centroid_var, spectral_centroid_skew, spectral_centroid_kurtosis, spectral_centroid_median, spectral_centroid_min, spectral_centroid_max = extract_statistics(spectral_centroid)\n",
    "            spec_bandwith_mean, spec_bandwith_var, spec_bandwith_skew, spec_bandwith_kurtosis, spec_bandwith_median, spec_bandwith_min, spec_bandwith_max = extract_statistics(spec_bandwith)\n",
    "            flatness_mean, flatness_var, flatness_skew, flatness_kurtosis, flatness_median, flatness_min, flatness_max = extract_statistics(flatness)\n",
    "            rolloff_mean, rolloff_var, rolloff_skew, rolloff_kurtosis, rolloff_median, rolloff_min, rolloff_max = extract_statistics(rolloff)\n",
    "            zero_crossing_rate_mean, zero_crossing_rate_var, zero_crossing_rate_skew, zero_crossing_rate_kurtosis, zero_crossing_rate_median, zero_crossing_rate_min, zero_crossing_rate_max = extract_statistics(zero_crossing_rate)\n",
    "            oenv_mean, oenv_var, oenv_skew, oenv_kurtosis, oenv_median, oenv_min, oenv_max = extract_statistics(oenv)\n",
    "            tempogram_mean, tempogram_var, tempogram_skew, tempogram_kurtosis, tempogram_median, tempogram_min, tempogram_max = extract_statistics(tempogram)\n",
    "            ac_global_mean, ac_global_var, ac_global_skew, ac_global_kurtosis, ac_global_median, ac_global_min, ac_global_max = extract_statistics(ac_global)                                                              \n",
    "            \n",
    "            features[i][0] = avg_shot_length\n",
    "            features[i][1] = color_var\n",
    "            features[i][2] = light_key\n",
    "            features[i][3] = mot_content   \n",
    "            #print('Video')\n",
    "            features[i][4] = mfccs_mean\n",
    "            features[i][5] = mfccs_var \n",
    "            features[i][6] = mfccs_skew\n",
    "            features[i][7] = mfccs_kurtosis\n",
    "            features[i][8] = mfccs_median\n",
    "            features[i][9] = mfccs_min\n",
    "            features[i][10] = mfccs_max\n",
    "            #print('MFCC')\n",
    "            features[i][11] = chroma_stft_mean\n",
    "            features[i][12] = chroma_stft_var\n",
    "            features[i][13] = chroma_stft_skew\n",
    "            features[i][14] = chroma_stft_kurtosis\n",
    "            features[i][15] = chroma_stft_median\n",
    "            features[i][16] = chroma_stft_min\n",
    "            features[i][17] = chroma_stft_max\n",
    "            #print('Chroma')\n",
    "            features[i][18] = mel_mean\n",
    "            features[i][19] = mel_var\n",
    "            features[i][20] = mel_skew\n",
    "            features[i][21] = mel_kurtosis\n",
    "            features[i][22] = mel_median\n",
    "            features[i][23] = mel_min\n",
    "            features[i][24] = mel_max\n",
    "            #print('Mel')\n",
    "            features[i][25] = contrast_mean\n",
    "            features[i][26] = contrast_var\n",
    "            features[i][27] = contrast_skew\n",
    "            features[i][28] = contrast_kurtosis\n",
    "            features[i][29] = contrast_median\n",
    "            features[i][30] = contrast_min\n",
    "            features[i][31] = contrast_max\n",
    "            #print('Contrast')\n",
    "            features[i][32] = tonnetz_mean\n",
    "            features[i][33] = tonnetz_var\n",
    "            features[i][34] = tonnetz_skew\n",
    "            features[i][35] = tonnetz_kurtosis\n",
    "            features[i][36] = tonnetz_median\n",
    "            features[i][37] = tonnetz_min\n",
    "            features[i][38] = tonnetz_max\n",
    "            #print('Tonnetz')\n",
    "            features[i][39] = tempo_bpm \n",
    "            #print('Tempo')\n",
    "            features[i][40] = spectral_centroid_mean\n",
    "            features[i][41] = spectral_centroid_var\n",
    "            features[i][42] = spectral_centroid_skew\n",
    "            features[i][43] = spectral_centroid_kurtosis\n",
    "            features[i][44] = spectral_centroid_median\n",
    "            features[i][45] = spectral_centroid_min\n",
    "            features[i][46] = spectral_centroid_max\n",
    "            #print('Spectral Centroid')\n",
    "            features[i][47] = spec_bandwith_mean\n",
    "            features[i][48] = spec_bandwith_var\n",
    "            features[i][49] = spec_bandwith_skew\n",
    "            features[i][50] = spec_bandwith_kurtosis\n",
    "            features[i][51] = spec_bandwith_median\n",
    "            features[i][52] = spec_bandwith_min\n",
    "            features[i][53] = spec_bandwith_max            \n",
    "            #print('Spectral Bandwith')\n",
    "            features[i][54] = flatness_mean\n",
    "            features[i][55] = flatness_var\n",
    "            features[i][56] = flatness_skew\n",
    "            features[i][57] = flatness_kurtosis\n",
    "            features[i][58] = flatness_median\n",
    "            features[i][59] = flatness_min\n",
    "            features[i][60] = flatness_max\n",
    "            #print('Flatness')\n",
    "            features[i][61] = rolloff_mean\n",
    "            features[i][62] = rolloff_var\n",
    "            features[i][63] = rolloff_skew\n",
    "            features[i][64] = rolloff_kurtosis\n",
    "            features[i][65] = rolloff_median\n",
    "            features[i][66] = rolloff_min\n",
    "            features[i][67] = rolloff_max\n",
    "            #print('Rolloff')\n",
    "            features[i][68] = zero_crossing_rate_mean\n",
    "            features[i][69] = zero_crossing_rate_var\n",
    "            features[i][70] = zero_crossing_rate_skew\n",
    "            features[i][71] = zero_crossing_rate_kurtosis\n",
    "            features[i][72] = zero_crossing_rate_median\n",
    "            features[i][73] = zero_crossing_rate_min            \n",
    "            features[i][74] = zero_crossing_rate_max\n",
    "            #print('Zero Crossing Rate')\n",
    "            features[i][75] = oenv_mean\n",
    "            features[i][76] = oenv_var\n",
    "            features[i][77] = oenv_skew\n",
    "            features[i][78] = oenv_kurtosis\n",
    "            features[i][79] = oenv_median\n",
    "            features[i][80] = oenv_min\n",
    "            features[i][81] = oenv_max\n",
    "            #print('Oenv')\n",
    "            features[i][82] = tempogram_mean\n",
    "            features[i][83] = tempogram_var\n",
    "            features[i][84] = tempogram_skew\n",
    "            features[i][85] = tempogram_kurtosis\n",
    "            features[i][86] = tempogram_median\n",
    "            features[i][87] = tempogram_min\n",
    "            features[i][88] = tempogram_max\n",
    "            #print('Tempogram')\n",
    "            features[i][89] = ac_global_mean\n",
    "            features[i][90] = ac_global_var\n",
    "            features[i][91] = ac_global_skew\n",
    "            features[i][92] = ac_global_kurtosis\n",
    "            features[i][93] = ac_global_median\n",
    "            features[i][94] = ac_global_min\n",
    "            features[i][95] = ac_global_max        \n",
    "            #print('Ac Global')\n",
    "            '''\n",
    "            del videodata\n",
    "            del smooth_scene_cuts                    \n",
    "    except Exception as e:\n",
    "        print(\"error: {0}\".format(e))\n",
    "        pass    \n",
    "\n",
    "def extract_XY(trailer_ids, trailer_labels, folder, num_features = 4, num_genres = 9): #num_features = 96\n",
    "    n_cpus = multiprocessing.cpu_count()    \n",
    "    print('n_cpus:',n_cpus)      \n",
    "    Genres = []    \n",
    "    FullPlots = [] \n",
    "    max_movies = min(10,len(trailer_ids))\n",
    "    poster_images = np.zeros((max_movies, width, height, depth))\n",
    "    spectograms = np.zeros((max_movies, audio_channels, sr))\n",
    "    Y = np.zeros((max_movies, num_genres))  #  \n",
    "    features = np.zeros((max_movies, num_features))\n",
    "    movie_data = lmtd.get_data_by_trailer_ids(trailer_ids)\n",
    "    i=0\n",
    "    for _id in trailer_ids:  \n",
    "        if i < max_movies:     \n",
    "            print(i)                        \n",
    "            process_movie(movie_data, trailer_labels, _id, i, Y, features, Genres, FullPlots, spectograms) \n",
    "            img_path = \"/home/paulo/mestrado/posters/\" + folder + \"/\" + _id + \".jpg\"\n",
    "            try:\n",
    "                pil_img = image.load_img(img_path, target_size=(299,299))        \n",
    "                poster_images[i] = image.img_to_array(pil_img)             \n",
    "            except:\n",
    "                pass\n",
    "        i+=1            \n",
    "    X = features\n",
    "    print(X.shape)    \n",
    "    print(X)\n",
    "    print(Y.shape)\n",
    "    print(Y)\n",
    "    print(Genres)\n",
    "    return X, Y, Genres, FullPlots, poster_images, spectograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_trailer_ids = lmtd.train_ids\n",
    "validation_trailer_ids = lmtd.valid_ids\n",
    "test_trailer_ids = lmtd.test_ids\n",
    "all_ids = list()\n",
    "all_ids.extend(training_trailer_ids)\n",
    "all_ids.extend(validation_trailer_ids)\n",
    "all_ids.extend(test_trailer_ids)\n",
    "all_ids = set(all_ids)\n",
    "print('Set length movie_trailers:', len(all_ids))\n",
    "\n",
    "all_movie_titles = set()\n",
    "\n",
    "i = 0\n",
    "with tqdm(total=len(all_ids), file=sys.stdout) as pbar:\n",
    "        movie_data = lmtd.get_data_by_trailer_ids(all_ids)\n",
    "        for _id in all_ids:    \n",
    "            pbar.set_description('processed: %d' % (1 + i))\n",
    "            pbar.update(1)\n",
    "            # Returns a dictionary in which keys are the queried trailer_ids            \n",
    "            title_db = movie_data[_id]['Title']\n",
    "            all_movie_titles.add(title_db)\n",
    "        i+=1\n",
    "        \n",
    "print('Diferent movie titles:', len(all_movie_titles))\n",
    "print(all_movie_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, train_Genres, train_FullPlots, train_poster_images, train_spectograms = extract_XY(training_trailer_ids, lmtd.train_labels, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_spectograms.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Correlations among Variables and Output Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "\n",
    "name_to_index = {8: 'Action', 7: 'Adventure', 6: 'Comedy', 5: 'Crime', 4: 'Drama', 3: 'Horror', 2: 'Romance', 1: 'SciFi', 0: 'Thriller'}\n",
    "train_Genres_encoded = []\n",
    "for i in range(train_Y.shape[0]):\n",
    "    genres_in_movie = (train_Y[i] == 1)\n",
    "    genre_indexes = [i for i, x in enumerate(genres_in_movie) if x]\n",
    "    #print(genre_indexes)\n",
    "    genres_in_movie_dict = {k: v for k, v in name_to_index.items() if k in genre_indexes and len(genre_indexes)==1}    \n",
    "    genres_in_movie_dict = OrderedDict(sorted(genres_in_movie_dict.items(), key=operator.itemgetter(1)))    \n",
    "    genres_in_movie_str = ','.join(genres_in_movie_dict.values())\n",
    "    print(genres_in_movie_str)\n",
    "    #print(name_to_index[0])\n",
    "    train_Genres_encoded.append(genres_in_movie_str)\n",
    "  \n",
    "d = {'avg_shot_length': train_X[:,0], \n",
    "     'color_var': train_X[:,1], \n",
    "     'light_key': train_X[:,2], \n",
    "     'mot_content': train_X[:,3], \n",
    "     'mfccs_mean': train_X[:,4], \n",
    "     #'chroma_stft_mean': train_X[:,11], \n",
    "     'mel_mean': train_X[:,18], \n",
    "     #'contrast_mean': train_X[:,25], \n",
    "     #'tonnetz_mean': train_X[:,32], \n",
    "     'tempo_bpm': train_X[:,39],\n",
    "     #'spectral_centroid_mean': train_X[:,40],\n",
    "     #'spec_bandwith_mean': train_X[:,47],\n",
    "     'flatness_mean': train_X[:,54],\n",
    "     #'rolloff_mean': train_X[:,61],\n",
    "     'zero_crossing_rate_mean': train_X[:,68],\n",
    "     #'oenv_mean': train_X[:,75],\n",
    "     #'tempogram_mean': train_X[:,82],\n",
    "     #'ac_global_mean': train_X[:,89],\n",
    "     'genres': train_Genres_encoded}\n",
    "print(d)\n",
    "df = pd.DataFrame(data=d)\n",
    "print(df.head())\n",
    "sns.pairplot(df, hue=\"genres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X, val_Y, val_Genres, val_FullPlots, val_poster_images, val_spectograms = extract_XY(validation_trailer_ids, lmtd.valid_labels, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_Y, test_Genres, test_FullPlots, test_poster_images, test_spectograms = extract_XY(test_trailer_ids, lmtd.test_labels, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "val_X = scaler.transform(val_X)\n",
    "test_X = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "train_Genres_encoded = le.fit_transform(train_Genres) \n",
    "val_Genres_encoded = le.fit_transform(val_Genres) \n",
    "test_Genres_encoded = le.fit_transform(test_Genres) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_Genres_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_Genres_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_Genres_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Features on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select features\n",
    "feature_selection = ExtraTreesClassifier()\n",
    "feature_selection = feature_selection.fit(val_X, val_Y)\n",
    "print(feature_selection.feature_importances_)\n",
    "importances = feature_selection.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in feature_selection.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "doFeatureSelection = False\n",
    "if doFeatureSelection:\n",
    "    model = SelectFromModel(feature_selection, prefit=True)\n",
    "    train_X = model.transform(train_X)\n",
    "    val_X = model.transform(val_X)\n",
    "    test_X = model.transform(test_X)\n",
    "    print(train_X.shape)\n",
    "    print(val_X.shape)\n",
    "    print(test_X.shape)\n",
    "\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(val_X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))    \n",
    "    \n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(50,50))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(val_X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(val_X.shape[1]), indices)\n",
    "plt.xlim([-1, val_X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best parameters on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(val_Genres_encoded))\n",
    "class_str = 'SVC'\n",
    "stratified = len(val_Genres_encoded) > 100\n",
    "\n",
    "C_range = 10. ** np.arange(-3, 3)\n",
    "if 'SVC' in class_str:    \n",
    "    gamma_range = 10. ** np.arange(-5, 4)\n",
    "    param_grid = dict(gamma=gamma_range, C=C_range, kernel=['linear', 'rbf'])\n",
    "elif 'Logistic' in class_str:\n",
    "    param_grid = dict(C=C_range)\n",
    "\n",
    "if stratified:\n",
    "    validation = StratifiedKFold(n_splits=2)\n",
    "else:\n",
    "    validation = KFold(n_splits=2) \n",
    "\n",
    "if 'SVC' in class_str:    \n",
    "    grid = GridSearchCV(SVC(), param_grid=param_grid, cv=validation, n_jobs=6)\n",
    "elif 'Logistic' in class_str:\n",
    "    grid = GridSearchCV(LogisticRegression(), param_grid=param_grid, cv=validation, n_jobs=6)\n",
    "grid.fit(val_X, val_Genres_encoded)\n",
    "\n",
    "print(\"Os melhores parametros %s com um score de %0.2f\" % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify\n",
    "C_best_param = grid.best_params_['C']\n",
    "if 'SVC' in class_str:    \n",
    "    kernel_best_param=grid.best_params_['kernel']\n",
    "    gamma_best_param = grid.best_params_['gamma']\n",
    "    classifier = SVC(C=C_best_param, gamma=gamma_best_param, kernel=kernel_best_param, class_weight='balanced', random_state=13)\n",
    "elif 'Logistic' in class_str:    \n",
    "    classifier = LogisticRegression(solver='sag', max_iter=100, C=C_best_param, random_state=13, class_weight='balanced', multi_class='ovr', n_jobs=6)\n",
    "\n",
    "ovr = OneVsRestClassifier(classifier)\n",
    "ovr.fit(train_X, train_Y)\n",
    "test_Ypred = ovr.predict(test_X)\n",
    "print(test_Ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average precision micro,macro, weighted:', evaluation.prauc(test_Y,test_Ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_names = ['Action', 'Adventure', 'Comedy', 'Crime', 'Drama', 'Horror', 'Romance', 'SciFi', 'Thriller']\n",
    "print(genres_names)\n",
    "print(np.sum(test_Y, axis=0))\n",
    "print(np.sum(test_Ypred, axis=0))\n",
    "\n",
    "df = {'genres': genres_names, 'true': np.sum(test_Y, axis=0), 'pred': np.sum(test_Ypred, axis=0)}\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(20,15), ncols=2)\n",
    "ax = sns.barplot(x='genres', y='true', data=df, ax=axs[0])\n",
    "ax.set_title(\"True Labels\")\n",
    "ax.set_xlabel('genres')\n",
    "\n",
    "sns.barplot(x='genres', y='pred', data=df, ax=axs[1]).set_title(\"Pred Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = 2\n",
    "\n",
    "n_classes = test_Y.shape[1]\n",
    "y_score = ovr.fit(train_X, train_Y).decision_function(test_X)\n",
    "print(n_classes)\n",
    "print(test_Genres)\n",
    "print(test_Y.shape)\n",
    "print(y_score.shape)\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(test_Y[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "#y_score_max = np.argmax(y_score, axis=1)\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(test_Y.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SoftAttention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_safe(x):\n",
    "    return K.clip(x, K.common._EPSILON, 1.0 - K.common._EPSILON)\n",
    "\n",
    "class Wrapper(Layer):\n",
    "    def __init__(self, layer, **kwargs):\n",
    "        self.layer = layer\n",
    "        super(Wrapper, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):       \n",
    "        super(Wrapper, self).build(input_shape)  # Be sure to call this somewhere!   \n",
    "       \n",
    "    def call(self, x):\n",
    "        super(Wrapper, self).call(x)\n",
    "\n",
    "class ProbabilityTensor(Wrapper):\n",
    "    \"\"\" function for turning 3d tensor to 2d probability matrix, which is the set of a_i's \"\"\"\n",
    "    def __init__(self, dense_function=None, *args, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.input_spec = [tf.keras.layers.InputSpec(ndim=3)]\n",
    "        #layer = TimeDistributed(dense_function) or TimeDistributed(Dense(1, name='ptensor_func'))\n",
    "        layer = TimeDistributed(Dense(1, name='ptensor_func'))\n",
    "        super(ProbabilityTensor, self).__init__(layer, *args, **kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.input_spec = [tf.keras.layers.InputSpec(shape=input_shape)]\n",
    "        if K._BACKEND == 'tensorflow':\n",
    "            if not input_shape[1]:\n",
    "                raise Exception('When using TensorFlow, you should define '\n",
    "                                'explicitly the number of timesteps of '\n",
    "                                'your sequences.\\n'\n",
    "                                'If your first layer is an Embedding, '\n",
    "                                'make sure to pass it an \"input_length\" '\n",
    "                                'argument. Otherwise, make sure '\n",
    "                                'the first layer has '\n",
    "                                'an \"input_shape\" or \"batch_input_shape\" '\n",
    "                                'argument, including the time axis.')\n",
    "\n",
    "        if not self.layer.built:\n",
    "            self.layer.build(input_shape)\n",
    "            self.layer.built = True\n",
    "        super(ProbabilityTensor, self).build(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # b,n,f -> b,n\n",
    "        #       s.t. \\sum_n n = 1\n",
    "        if isinstance(input_shape, (list,tuple)) and not isinstance(input_shape[0], int):\n",
    "            input_shape = input_shape[0]\n",
    "\n",
    "        return (input_shape[0], input_shape[1])\n",
    "\n",
    "    def squash_mask(self, mask):\n",
    "        if K.ndim(mask) == 2:\n",
    "            return mask\n",
    "        elif K.ndim(mask) == 3:\n",
    "            return K.any(mask, axis=-1)\n",
    "\n",
    "    def compute_mask(self, x, mask=None):\n",
    "        if mask is None:\n",
    "            return None\n",
    "        return self.squash_mask(mask)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        energy = K.squeeze(self.layer(x), 2)\n",
    "        p_matrix = K.softmax(energy)\n",
    "        if mask is not None:\n",
    "            mask = self.squash_mask(mask)\n",
    "            p_matrix = make_safe(p_matrix * mask)\n",
    "            p_matrix = (p_matrix / K.sum(p_matrix, axis=-1, keepdims=True))*mask\n",
    "        return p_matrix\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {}\n",
    "        base_config = super(ProbabilityTensor, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "class SoftAttentionConcat(ProbabilityTensor):\n",
    "    '''This will create the context vector and then concatenate it with the last output of the LSTM'''\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # b,n,f -> b,f where f is weighted features summed across n\n",
    "        return (input_shape[0], 2*input_shape[2])\n",
    "\n",
    "    def compute_mask(self, x, mask=None):\n",
    "        if mask is None or mask.ndim==2:\n",
    "            return None\n",
    "        else:\n",
    "            raise Exception(\"Unexpected situation\")\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # b,n,f -> b,f via b,n broadcasted\n",
    "        p_vectors = K.expand_dims(super(SoftAttentionConcat, self).call(x, mask), 2)\n",
    "        expanded_p = K.repeat_elements(p_vectors, K.int_shape(x)[2], axis=2)\n",
    "        context = K.sum(expanded_p * x, axis=1)\n",
    "        last_out = x[:, -1, :]\n",
    "        return K.concatenate([context, last_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "all_data.extend(train_FullPlots)\n",
    "all_data.extend(val_FullPlots)\n",
    "all_data.extend(test_FullPlots)\n",
    "print(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = setup_tokenizer(all_data)\n",
    "word_index = tokenizer.word_index\n",
    "embeddings_index = setup_glove_embeddings()\n",
    "embedding_matrix = setup_embeddings_matrices(embeddings_index, word_index)\n",
    "embedding_layer = setup_embedding_layer(word_index, embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "X_train_text = sequence.pad_sequences(tokenizer.texts_to_sequences(train_FullPlots), maxlen=maxlen)\n",
    "X_val_text = sequence.pad_sequences(tokenizer.texts_to_sequences(val_FullPlots), maxlen=maxlen)\n",
    "X_test_text = sequence.pad_sequences(tokenizer.texts_to_sequences(test_FullPlots), maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train shape:', X_train_text.shape)\n",
    "print('x_val shape:', X_val_text.shape)\n",
    "print('x_test shape:', X_test_text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Branch 1 - RNN for Text (Full Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(max_sentence_len,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "# RNN\n",
    "lstm = Bidirectional(LSTM(lstm_size, return_sequences=True, recurrent_dropout=recurrent_dropout))(embedded_sequences)\n",
    "attention_1 = SoftAttentionConcat()(lstm)\n",
    "batch1 = BatchNormalization()(attention_1)\n",
    "\n",
    "branch_1 = Dense(512, activation='relu')(batch1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Branch 2 - CNN for images (Poster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image input branch - a pre-trained Inception module followed by an added fully connected layer\n",
    "base_model = applications.InceptionV3(weights='imagenet', include_top=False)\n",
    "# Freeze Inception's weights - we don't want to train these\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# add a fully connected layer after Inception - we do want to train these\n",
    "branch_2 = base_model.output\n",
    "branch_2 = GlobalAveragePooling2D()(branch_2)\n",
    "branch_2 = Dense(512, activation='relu')(branch_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Branch 3 - CNN for spectogram image (Audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A mel-spectrogram layer\n",
    "audio_inputs = Input(shape=audio_input_shape)\n",
    "branch3 = Melspectrogram(n_dft=512, n_hop=256,\n",
    "                         padding='same', sr=sr, n_mels=128,\n",
    "                         fmin=0.0, fmax=sr/2, power_melgram=1.0,\n",
    "                         return_decibel_melgram=False, trainable_fb=False,\n",
    "                         trainable_kernel=False,\n",
    "                         name='trainable_stft')(audio_inputs)\n",
    "# Maybe some additive white noise.\n",
    "branch3 = AdditiveNoise(power=0.2)(branch3)\n",
    "# If you wanna normalise it per-frequency\n",
    "branch3 = Normalization2D(str_axis='freq')(branch3) # or 'channel', 'time', 'batch', 'data_sample'\n",
    "#CNN\n",
    "branch3 = Conv2D(32, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform')(branch3)\n",
    "branch3 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform')(branch3)\n",
    "branch3 = BatchNormalization()(branch3)\n",
    "branch3 = MaxPooling2D(pool_size=(2, 2))(branch3)\n",
    "branch3 = Dropout(0.25)(branch3)\n",
    "branch3 = Conv2D(64, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform')(branch3)\n",
    "branch3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform')(branch3)\n",
    "branch3 = BatchNormalization()(branch3)\n",
    "branch3 = MaxPooling2D(pool_size=(2, 2))(branch3)\n",
    "branch3 = Dropout(0.25)(branch3)\n",
    "branch3 = Conv2D(64, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform')(branch3)\n",
    "branch3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform')(branch3)\n",
    "branch3 = BatchNormalization()(branch3)\n",
    "branch3 = MaxPooling2D(pool_size=(2, 2))(branch3)\n",
    "branch3 = Dropout(0.25)(branch3)\n",
    "branch3 = GlobalAveragePooling2D()(branch3)\n",
    "branch3 = Dense(512, activation='relu')(branch3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Branch 4 - LTMD9 Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be sure to update your LMTD_PATH\n",
    "'''\n",
    "LMTD_PATH = '/home/paulo/mestrado/lmtd'\n",
    "features_path = os.path.join(LMTD_PATH, 'features', 'lmtd9_resnet152.pickle')\n",
    "lmtd.load_precomp_features(features_file=features_path)\n",
    "\n",
    "x_valid_lmtd, x_valid_len, y_valid_lmtd, valid_ids = lmtd.get_split('valid')\n",
    "x_train_lmtd, x_train_len, y_train_lmtd, train_ids = lmtd.get_split('train')\n",
    "x_test_lmtd,  x_test_len,  y_test_lmtd,  test_ids  = lmtd.get_split('test')\n",
    "\n",
    "inputs = Input(shape=(time_steps, nb_features))\n",
    "branch4 = BatchNormalization()(inputs)\n",
    "branch4 = Convolution1D(conv_filters, kernel_size=3)(branch4)\n",
    "branch4 = BatchNormalization()(branch4)\n",
    "branch4 = Activation('relu')(branch4)\n",
    "branch4 = GlobalMaxPooling1D()(branch4)\n",
    "branch4 = Dropout(dropout)(branch4)\n",
    "branch4 = Dense(512, activation='relu')(branch4)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# join branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = np.max(train_Genres_encoded) + 1\n",
    "print(num_classes)\n",
    "\n",
    "y_train = to_categorical(train_Genres_encoded, num_classes=num_classes)\n",
    "y_val = to_categorical(val_Genres_encoded, num_classes=num_classes)\n",
    "y_test = to_categorical(val_Genres_encoded, num_classes=num_classes)\n",
    "\n",
    "print(y_train)\n",
    "print(y_val)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the text input branch and the image input branch and add another fully connected layer\n",
    "joint = merge([branch_1, branch_2, branch3], mode='concat')\n",
    "joint = Dense(2048, activation='relu')(joint)\n",
    "joint = Dropout(0.5)(joint)\n",
    "predictions = Dense(num_classes, activation='softmax', kernel_initializer='glorot_uniform')(joint)\n",
    "\n",
    "full_model = Model(inputs=[base_model.input, sequence_input, audio_inputs], outputs=[predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "print('Start:',start_time)\n",
    "\n",
    "#TIP: set tensorflow number of threads (check number of cores in CPU and use half of maximum)\n",
    "number_gpus = number_gpus\n",
    "number_cpus = number_cpus\n",
    "with tf.Session(config = tf.ConfigProto(device_count={'GPU': number_gpus, 'CPU': number_cpus}, log_device_placement=True)) as sess:\n",
    "    K.set_session(sess)\n",
    "    \n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    full_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    history = full_model.fit([train_poster_images, X_train_text, train_spectograms], y_train,\n",
    "                         epochs=max_epochs, batch_size=batch_size, verbose=1, \n",
    "                         validation_data=([val_poster_images, X_val_text, val_spectograms], y_val), \n",
    "                         shuffle=True)\n",
    "    \n",
    "    full_model.save('MovieGenreClassifier.h5')\n",
    "    \n",
    "    y_pred_test = model.predict([test_poster_images, X_test_text, test_spectograms])    \n",
    "    result = evaluation.prauc(y_test, y_pred_test)\n",
    "    \n",
    "    print_result(result)\n",
    "        \n",
    "end_time = datetime.datetime.now()\n",
    "print('End:',start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
